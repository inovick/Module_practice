---
title: "Module 12"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(curl)
library(ggplot2)
library(gridExtra)
library(manipulate)
library(lmodel2)

f <- curl("https://raw.githubusercontent.com/fuzzyatelin/fuzzyatelin.github.io/master/AN588_Fall21/zombies.csv")
d <- read.csv(f, header = TRUE, sep = ",", stringsAsFactors = FALSE)
head(d)

plot(data = d, height ~ weight)
```
##Challenge 1: Covariance
```{r}
w <- d$weight
h <- d$height
n <- length(w)  # or length(h)
cov_wh <- sum((w - mean(w)) * (h - mean(h)))/(n - 1)
cov_wh

#Also can use:
cov(w, h)
```
##Challenge 2: Calculate the correlation between zombie height and weight.
```{r}
sd_w <- sd(w)
sd_h <- sd(h)
cor_wh <- cov_wh/(sd_w * sd_h)
cor_wh

#Again, also can use:
cor(w, h)

#For using Pearson's:
cor(w, h, method = "pearson")

#For Kendall or Spearman:
cor(w, h, method = "kendall")
cor(w, h, method = "spearman")
```
##Regression: Calculating by hand
```{r}
y <- h - mean(h)
x <- w - mean(w)
z <- data.frame(cbind(x, y))
g <- ggplot(data = z, aes(x = x, y = y)) + geom_point()
g
```
##Finding the best slope:
```{r}
slope.test <- function(beta1) {
    g <- ggplot(data = z, aes(x = x, y = y))
    g <- g + geom_point()
    g <- g + geom_abline(intercept = 0, slope = beta1, size = 1, colour = "blue",
        alpha = 1/2)
    ols <- sum((y - beta1 * x)^2)
    g <- g + ggtitle(paste("Slope = ", beta1, "\nSum of Squared Deviations = ",
        round(ols, 3)))
    g
}


#Can type into console
manipulate(slope.test(beta1), beta1 = slider(-1, 1, initial = 0, step = 0.005))

```
##Similarly, analystically, from the Books of R:
```{r}
beta1 <- cor(w, h) * (sd(h)/sd(w))
beta1

beta1 <- cov(w, h)/var(w)
beta1

beta1 <- sum((h - mean(h)) * (w - mean(w)))/sum((w - mean(w))^2)
beta1

beta0 <- mean(h) - beta1 * mean(w)
beta0
```
##Making this process easier by using the lm function:
```{r}
m <- lm(height ~ weight, data = d)
m

names(m)
m$coefficients
head(m$model)
```
##In {ggplot}, we can easily create a plot that adds the linear model along with confidence intervals around the estimated value of y, or at each x. Those intervals are important for when we move on to talking about inference in the regression context.
```{r}
g <- ggplot(data = d, aes(x = weight, y = height))
g <- g + geom_point()
g <- g + geom_smooth(method = "lm", formula = y ~ x)
g
```
##Model II regression
```{r}
library(lmodel2)  # load the lmodel2 package
# Run the regression
mII <- lmodel2(height ~ weight, data = d, range.y = "relative", range.x = "relative",
    nperm = 1000)
mII

plot(mII, "OLS")

plot(mII, "RMA")

plot(mII, "SMA")

plot(mII, "MA")
```
##Note that, here, running lmodel2() and using OLS to detemine the best coefficients yields equivalent results to our Model I regression done above using lm()
```{r}
mI <- lm(height ~ weight, data = d)
summary(mI)

library(lmodel2)
par(mfrow = c(1, 2))
plot(mII, main = "lmodel2() OLS")
plot(data = d, height ~ weight, main = "lm()")
abline(mI)
```
##Challenge 3: Using zombies dataset
```{r}
plot(data = d, height ~ age)
head(d)

beta1 <- cor(d$height, d$age) * sd(d$height)/sd(d$age)
beta1

beta0 <- mean(d$height) - beta1 * mean(d$age)
beta0

m <- lm(height ~ age, data = d)
m
```
##Statistical inference in regression: 
###Once we have our linear model and associated regression coefficients, we want to know a bit more about it. First, we want to be able to evaluate whether there is statistical evidence that there is indeed a relationship between these variables. If so, then our regression coefficients can indeed allow us to estimate or predict the value of one variable given another. Additionally, we also would like to be able to extend our estimates from our sample out to the population they are drawn from. These next steps involve the process of statistical inference.

The output of the lm() function provides a lot of information useful for inference. Run the command summary() on the output of lm(data=d,height~weight)
```{r}
m <- lm(data = d, height ~ weight)
summary(m)
```
##Another output is the standard error of the estimate of each regression coefficient, along with a corresponding t value and p value. Recall that t statistics are calculated as the difference between an observed and expected value divided by a standard error. The p value comes from evaluating the magnitude of the t statistic against a t distribution with n-2 degrees of freedom. We can confirm this by hand calculating t and p based on the estimate and the standard error of the estimate.
```{r}
t <- coef(summary(m))
t <- data.frame(unlist(t))
colnames(t) <- c("Est", "SE", "t", "p")
t

t$calct <- (t$Est - 0)/t$SE
t$calcp <- 2 * pt(t$calct, df = 998, lower.tail = FALSE)  # x2 because is 2-tailed test
t
```
##We can get confidence intervals for our estimates easily, too, using either the approach weâ€™ve used before by hand or by using a built in function.
```{r}
t$lower <- t$Est - qt(0.975, df = 998) * t$SE
t$upper <- t$Est + qt(0.975, df = 998) * t$SE
ci <- c(t$lower, t$upper)  # by hand
ci

ci <- confint(m, level = 0.95)  # using the results of lm()
ci
```
##Challenge 4: 
    If zombie weight is measured in pounds and zombie height is measured in inches, what is the expected height of a zombie weighing 150 pounds?
    What is the predicted difference in height between a zombie weighing 180 and 220 pounds?
```{r}
beta0 <- t$Est[1]
beta1 <- t$Est[2]
h_hat <- beta1 * 150 + beta0
h_hat

h_hat_difference <- (beta1 * 220 + beta0) - (beta1 * 180 + beta0)
h_hat_difference
```
##Predict function:
```{r}
m <- lm(data = d, height ~ weight)
h_hat <- predict(m, newdata = data.frame(weight = d$weight))
df <- data.frame(cbind(d$weight, d$height, h_hat))
names(df) <- c("x", "y", "yhat")
head(df)
```
```{r}
g <- ggplot(data = df, aes(x = x, y = yhat))
g <- g + geom_point()
g <- g + geom_point(aes(x = x, y = y), colour = "red")
g <- g + geom_segment(aes(x = x, y = yhat, xend = x, yend = y))
g
```
```{r}
ci <- predict(m, newdata = data.frame(weight = 150), interval = "confidence",
    level = 0.95)  # for a single value
ci

ci <- predict(m, newdata = data.frame(weight = d$weight), interval = "confidence",
    level = 0.95)  # for a vector of values
head(ci)

df <- cbind(df, ci)
names(df) <- c("x", "y", "yhat", "CIfit", "CIlwr", "CIupr")
head(df)
```
```{r}
g <- ggplot(data = df, aes(x = x, y = y))
g <- g + geom_point(alpha = 1/2)
g <- g + geom_line(aes(x = x, y = CIfit), colour = "black")
g <- g + geom_line(aes(x = x, y = CIlwr), colour = "blue")
g <- g + geom_line(aes(x = x, y = CIupr), colour = "blue")
g
```
##The same predict() function also allows us to easily generate prediction intervals for values of y at each x.
```{r}
pi <- predict(m, newdata = data.frame(weight = 150), interval = "prediction",
    level = 0.95)  # for a single value
pi

pi <- predict(m, newdata = data.frame(weight = d$weight), interval = "prediction",
    level = 0.95)  # for a vector of values
head(pi)

df <- cbind(df, pi)
names(df) <- c("x", "y", "yhat", "CIfit", "CIlwr", "CIupr", "PIfit", "PIlwr",
    "PIupr")
head(df)

g <- g + geom_line(data = df, aes(x = x, y = PIlwr), colour = "red")
g <- g + geom_line(data = df, aes(x = x, y = PIupr), colour = "red")
g
```
##Challenge 5: Construct a linear model for the regression of zombie height on age and predict the mean height, the 95% confidence interval (CI) around the predicted mean height, and the 95% prediction interval (PI) around that mean for a vector of zombie ages, v <- seq(from=10, to=30, by=1). Then, plot your points, your regression line, and lines for the lower and upper limits of the CI and of the PI.
```{r}
v <- seq(from = 10, to = 30, by = 1)
m <- lm(data = d, height ~ age)
ci <- predict(m, newdata = data.frame(age = v), interval = "confidence", level = 0.95)
pi <- predict(m, newdata = data.frame(age = v), interval = "prediction", level = 0.95)
plot(data = d, height ~ age)
lines(x = v, y = ci[, 1], col = "black")
lines(x = v, y = ci[, 2], col = "blue")
lines(x = v, y = ci[, 3], col = "blue")
lines(x = v, y = pi[, 2], col = "red")
lines(x = v, y = pi[, 3], col = "red")
```
```{r}
# or
require(gridExtra)
require(ggplot2)
df <- data.frame(cbind(v, ci, pi))
names(df) <- c("age", "CIfit", "CIlwr", "CIupr", "PIfit", "PIlwr", "PIupr")
head(df)

g1 <- ggplot(data = d, aes(x = age, y = height))
g1 <- g1 + geom_point(alpha = 1/2)
g1 <- g1 + geom_line(data = df, aes(x = v, y = CIfit), colour = "black", lwd = 1)
g1 <- g1 + geom_line(data = df, aes(x = v, y = CIlwr), colour = "blue")
g1 <- g1 + geom_line(data = df, aes(x = v, y = CIupr), colour = "blue")
g1 <- g1 + geom_line(data = df, aes(x = v, y = PIlwr), colour = "red")
g1 <- g1 + geom_line(data = df, aes(x = v, y = PIupr), colour = "red")
g2 <- ggplot(data = d, aes(x = age, y = height))
g2 <- g2 + geom_point(alpha = 1/2)
g2 <- g2 + geom_smooth(method = "lm", formula = y ~ x)
grid.arrange(g1, g2, ncol = 2)
```

